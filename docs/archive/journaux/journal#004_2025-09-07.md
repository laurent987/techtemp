# Journal #004 — MQTT Ingestion Pipeline (2025-09-07)

## Objective

Implement the **MQTT → SQLite ingestion pipeline** for the service-app:
- Complete MQTT message processing pipeline
- Data validation and transformation
- MQTT Client + Repository Pattern integration
- End-to-end integration tests

## Context

Journal #003 delivered **solid foundations**:
- ✅ Configuration + validation (71/71 tests)
- ✅ SQLite + Schema with explicit columns
- ✅ Repository Pattern + Data Access Layer
- ✅ Robust MQTT Client

Now we need to **connect MQTT to storage** for a complete pipeline.

## Decisions

- **Pipeline architecture**: MQTT → Parse → Validate → Transform → Repository → SQLite
- **Ingestion modules**: `parseTopic.js`, `validateReading.js`, `ingestMessage.js`
- **Error handling**: Detailed logs + metrics + graceful fallback
- **Performance**: Asynchronous processing + batch processing if needed
- **Idempotence**: Deduplication via unique `msg_id`
- **End-to-end tests**: Real MQTT → Verifiable database

## Scope

### ✅ To Implement

**Ingestion modules:**
- `src/ingestion/parseTopic.js`:
  - Parse MQTT topic according to contract: `home/{homeId}/sensors/{deviceId}/reading`
  - Format validation + `{homeId, deviceId}` extraction
  - Error handling with explicit messages

- `src/ingestion/validateReading.js`:
  - JSON payload validation with detailed Joi schema
  - Data normalization (types, ranges)
  - Transform `temperature_c`/`humidity_pct` → `temperature`/`humidity`

- `src/ingestion/ingestMessage.js`:
  - Complete pipeline: `(topic, payload) → DB`
  - Module orchestration + error handling
  - Automatic device creation if needed
  - Deduplication and idempotence

**Complete integration:**
- MQTT Client + Ingestion Pipeline integration
- Main service with proper startup/shutdown
- Unified configuration (MQTT + DB + HTTP)

**Integration tests:**
- Complete pipeline with real MQTT broker
- End-to-end validation: MQTT → SQLite
- Load tests and error handling
- Deduplication and performance

### ❌ Out of Scope
- HTTP Server (Journal #005)
- REST API endpoints (Journal #005)
- Advanced monitoring (Journal #006)
- Production deployment (Journal #007)

## Implementation Plan

### Phase 1: Parse Topic
- [ ] Write `test/ingestion/parseTopic.test.js`:
  - Valid topics according to MQTT contract
  - Invalid topics → explicit errors
  - Edge cases (special characters, lengths)
- [ ] Implement `buildTopicParser()` and associated functions
- [ ] Validation against contract 001

### Phase 2: Validate Reading
- [ ] Write `test/ingestion/validateReading.test.js`:
  - Valid JSON payloads (types, ranges)
  - Invalid payloads → detailed Joi errors
  - Transformation and normalization
- [ ] Implement `validateReadingPayload()` with Joi schema
- [ ] Performance tests and edge cases

### Phase 3: Ingest Message
- [ ] Write `test/ingestion/ingestMessage.test.js`:
  - Complete pipeline with mocks
  - Error handling at each step
  - Automatic device creation
  - Deduplication via `msg_id`
- [ ] Implement `createIngestor()` with orchestration
- [ ] Integration with Repository Pattern

### Phase 4: End-to-end tests
- [ ] Write `test/integration/mqtt-to-db.test.js`:
  - Complete pipeline: MQTT → SQLite
  - Aedes broker + temporary database
  - Stored data validation
  - Load tests and concurrency
- [ ] Main service with complete lifecycle
- [ ] Updated demo with complete pipeline

## Expected Artifacts

- `service-app/src/ingestion/parseTopic.js` (complete implementation)
- `service-app/src/ingestion/validateReading.js` (Joi validation)
- `service-app/src/ingestion/ingestMessage.js` (pipeline orchestration)
- `service-app/test/ingestion/` (unit tests for each module)
- `service-app/test/integration/mqtt-to-db.test.js` (end-to-end tests)
- `service-app/src/main.js` (updated main service)
- Updated demos with complete pipeline

## Acceptance Criteria

✅ **Parse Topic**: `buildTopicParser()` extracts `{homeId, deviceId}` according to contract  
✅ **Validate Reading**: `validateReadingPayload()` validates and transforms data  
✅ **Ingest Message**: `createIngestor()` orchestrates complete pipeline  
✅ **Integration**: MQTT → SQLite pipeline functional end-to-end  
✅ **Tests**: New tests pass + existing tests (71+) maintained  
✅ **Performance**: Smooth processing of serial/parallel messages  
✅ **Robustness**: Graceful error handling + detailed logs  

## Planned Commands

```bash
# Ingestion-specific tests
npm run test -- ingestion

# Integration tests
npm run test -- integration

# Complete tests
npm test

# Complete pipeline demo
node examples/service-complete-demo.js
```

## Useful Links

- **Journal #003**: SQLite + Config foundations (solid base)
- **Contract 001**: MQTT and DB specifications (sections 1 & 2)
- **Architecture**: MQTT Client + Repository + Data Access already available
- **Joi schemas**: For payload validation and transformation

---

📝 **Pipeline Architecture**:
```
MQTT Topic + Payload 
    ↓ parseTopic()
{homeId, deviceId} + Payload
    ↓ validateReading() 
{homeId, deviceId} + ValidatedReading
    ↓ ingestMessage()
Repository.create() → DataAccess → SQLite
```

📝 **Next**: Journal #005 — HTTP Server + REST API

---

## 🎯 **MEASURABLE OBJECTIVES**

**Success metrics:**
- **Tests**: 71+ tests pass (maintain + new)
- **Pipeline**: <100ms per MQTT message on average
- **Robustness**: 0% data loss on valid messages
- **Integration**: Complete demo functional MQTT → DB → Query

**Expected benefits:**
- Service-app capable of receiving and storing sensor data
- Foundation for HTTP API (Journal #005)
- Scalable architecture for monitoring and alerts
- Robust validation and testing for production
